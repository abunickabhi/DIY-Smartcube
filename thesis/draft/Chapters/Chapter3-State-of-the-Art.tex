% Chapter Template

\chapter{State of the Art} % Main chapter title

\label{Chapter3} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}


\section{Introduction}

TODO, be a *neutral* presentation of the current state of this technology. Give a big information dump to the reader.


\section{Commercial Smartcubes}

At the time of writing, there were four major smartcubes on the market: the Giiker Cube, the Go Cube, the Gans 356i, and the Rubik's Connected.

\subsection{Giiker Cube}
TODO Describe the Giiker Cube and its features. Explain the inner workings using the FCC pictures.

\subsection{Go Cube}
TODO Describe the Go Cube and its features. Explain the inner workings using the FCC pictures.

\subsection{Gans 356i}
TODO Describe the Gans 356i Cube and its features. Explain the inner workings using the FCC pictures.

\subsection{Rubik's Connected}
TODO Describe the Gans 356i Cube and its features. Explain the inner workings using the FCC pictures.


\section{Academia}

\subsection{Rotary Encoders + Bluetooth}
TODO Discuss the viability of using rotary encoders + bluetooth for making a smart cube. Make sure to discuss the difference between absolute/relative rotary encoders.


\subsection{Sound}
TODO discuss the viability of using sound for making a smart cube.

\subsubsection{Google's "Data Over Sound" Project}
TODO discuss the Google's "data over sound" project and its applicability to this problem space.


\subsection{Computer Vision}
Computer Vision refers to the "field of Artificial Intelligence (AI) that enables computers and systems to derive meaningful information from digital images, videos, and other visual inputs." \cite{ibm-cv-definition}
Since human manipulation of a Rubik's Cube is a physical, observable process, Computer Vision algorithms could be developed to extract face turn information from videos of Rubik's Cube solutions.

This section summarizes some of the relevant research in this area, including computer vision algorithms capable of extracting individual sticker colors from video, measuring the angle of rotation of a specific face, and detection of entire face turns and face turn sequences.

\subsubsection{Sticker Color Classification}
In 2015, Jay Hack, an graduate student studying Computer Science at Stanford developed a neural network capable of recognizing the colors of a Rubik's Cube face from video in various lighting conditions.
His algorithm could classify frames within 7 milliseconds with 92\% accuracy. \cite{jay-hack-opencv}

\subsubsection{Measuring a Face's Angle of Rotation}
In 2019, OpenAI et al. published a viral video of a robot hand that had taught itself to solve a Rubik's Cube.
While the final, most successful version of the robot hand's software used a Giiker Cube to obtain the current rotational state of the cube, OpenAI et al. also researched the viability of tracking a Rubik's Cube's position using only computer vision.
Their most successful vision-only algorithm measured only the rotation angle of the top-most face on the Rubik's Cube and assumed significant hardware requirements: a modified sticker set for the Rubik's Cube, a well-lit environment, three strategically positioned RBG Basler cameras, and a neural network trained on "a pool of optimizer nodes, each of which uses 8 NVIDIA V100 GPUs and 64 CPU cores".
At peak performance, their vision-only algorithm's average error (the difference between the predicted face angle and the actual face angle) was 15.92$^\circ$, nearly three times the 5.90$^\circ$ average error of the hardware-based face angle measurement. \cite{openai2019rubiks}

\subsubsection{Classification of Single Moves and Entire Move Sequences}
In 2020, Junshen Kevin Chen, Wanze Xie, and Zhouheng Sun, graduate Computer Science students at Stanford created the DeepCube dataset consisting of over 20,000 videos of Rubik's Cube face turns with consistent lighting and backgrounds. 
They also built a neural network to classify the videos with the face turn they contained.
Their best performing model only made "one mistake every 15 moves" which corresponds to a 93.3\% accuracy. \cite{chen-deep-cube-dataset}


\subsection{Other Approaches}

TODO In this section I'm laying out a structure for discussing several of the options I looked into but ultimately disregarded. Should that go in the State of the Art chapter? or would it fit better in the Evaluation chapter to contrast against the potential of the sound-based implementation?

\subsubsection{RFID}
TODO discuss the viability of using RFID for making a smart cube.
\subsubsection{Magnetic Resonance}
TODO discuss the viability of using magnetic resonance for making a smart cube.
\subsubsection{Muscle-Tracking Armband}
TODO discuss the viability of using a muscle tracking armband for making a smart cube.


\section{Choice of Sound for My Thesis}

TODO This section might be large enough to merit its own chapter...
TODO Briefly detail the rationale for chosing to pursue a sound-based approach.