@online{forbes-rubik-merger,
  author   = {Verdon, Joan},
  title    = {Rubik’s Cube And Spin Master: A \$50 Million Deal With Endless Possibilities},
  url      = {https://www.forbes.com/sites/joanverdon/2020/11/15/rubiks-cube-and-spin-master-a-50-million-deal-with-endless-possibilities/},
  addendum = {(accessed: 10 August 2021)},
  keywords = {forbes,rubiks,units sold,merger}
}

@online{rubik-motivation,
  author   = {Rubik's Brand Ltd.},
  title    = {About Us},
  url      = {https://www.rubiks.com/en-us/about},
  addendum = {(accessed: 10 August 2021)},
  keywords = {erno rubik}
}

@online{rubik-patent,
  author   = {Rubik, Erno},
  title    = {Rubik's Cube Patent},
  url      = {https://www.hipo.gov.hu/hu/anim/pics/HU-170062.pdf},
  addendum = {(accessed: 10 August 2021)},
  keywords = {erno rubik,patent}
}

@online{rubik-population-reached,
  author   = {Rubik's Brand Ltd.},
  title    = {The History of the Rubik's Cube},
  url      = {https://web.archive.org/web/20180908211659/https://www.rubiks.com/about/the-history-of-the-rubiks-cube},
  addendum = {(accessed: 10 August 2021)},
  keywords = {erno rubik,cube,history}
}

@article{openai2019rubiks,
  title   = {Solving Rubik's Cube with a Robot Hand},
  author  = {OpenAI and Ilge Akkaya and Marcin Andrychowicz and Maciek Chociej and Mateusz Litwin and Bob McGrew and Arthur Petron and Alex Paino and Matthias Plappert and Glenn Powell and Raphael Ribas and Jonas Schneider and Nikolas Tezak and Jerry Tworek and Peter Welinder and Lilian Weng and Qiming Yuan and Wojciech Zaremba and Lei Zhang},
  year    = {2019},
  journal = {arXiv preprint}
}

@mastersthesis{hoang-cube-theory-and-robotics,
  author = {Hoang, Le Thanh},
  title  = {Optimally Solving a Rubik's Cube Using Vision and Robotics},
  school = {Imperial College of London},
  year   = {2015}
}

@misc{hackrubik,
  title     = {Rubik's Cube Localization, Face Detection, and Interactive Solving},
  author    = {Hack, Jay and Shutzberg, Kevin},
  publisher = {unpublished}
}

@article{chendeepcube,
  title  = {DeepCube: Transcribing Rubik’s Cube Moves with Action Recognition},
  author = {Chen, Junshen Kevin and Xie, Wanze and Sun, Zhouheng}
}

@online{ibm-cv-definition,
  author   = {IBM},
  title    = {What is computer vision?},
  url      = {https://www.ibm.com/topics/computer-vision},
  addendum = {(accessed: 23 Sep 2021)},
  keywords = {ibm,computer vision,artificial intelligence}
}

@online{gans-356i-internals,
  author   = {Federal Communications Commission},
  title    = {FCC ID: 2AT27-GAN-3X3 - Internal photos},
  url      = {https://apps.fcc.gov/oetcf/eas/reports/ViewExhibitReport.cfm?mode=Exhibits&calledFromFrame=Y&application_id=B75M7i7IVYNksPluyUFB1Q%3D%3D&fcc_id=2AT27-GAN-3X3},
  addendum = {(accessed: 24 Sep 2021)}
}

@online{giiker-internals,
  author   = {Federal Communications Commission},
  title    = {FCC ID: 2ATHZ-SUPERCUBE - INT PHO},
  url      = {https://apps.fcc.gov/oetcf/eas/reports/ViewExhibitReport.cfm?mode=Exhibits&calledFromFrame=Y&application_id=xbxQDjxzoHU1WywTbpvIAQ%3D%3D&fcc_id=2ATHZ-SUPERCUBE},
  addendum = {(accessed: 24 Sep 2021)}
}

@online{gocube-internals,
  author   = {Federal Communications Commission},
  title    = {FCC ID: 2ASMEGC33 - Internal photos},
  url      = {https://apps.fcc.gov/oetcf/eas/reports/ViewExhibitReport.cfm?mode=Exhibits&calledFromFrame=Y&application_id=tdk9t6CDQWEFnu4P%2B1WEbg%3D%3D&fcc_id=2ASMEGC33},
  addendum = {(accessed: 24 Sep 2021)}
}

@online{rubiksconnect-internals,
  author   = {Federal Communications Commission},
  title    = {FCC ID: 2AWLXRBE001CC - Internal photos},
  url      = {https://apps.fcc.gov/oetcf/eas/reports/ViewExhibitReport.cfm?mode=Exhibits&calledFromFrame=Y&application_id=uh6hcVwqvJiiujSz4qFnzw%3D%3D&fcc_id=2AWLXRBE001CC},
  addendum = {(accessed: 24 Sep 2021)}
}

@online{eggins-giiker-internals,
  author   = {Eggins, Charlie and Eggins, Geoff},
  title    = {Giiker Cube Repair for Repeated Out of Sync Issues},
  url      = {https://swiftcubing.com/2019/10/14/giiker-cube-repair-for-repeated-out-of-sync-issues/},
  addendum = {(accessed: 24 Sep 2021)}
} 

@online{giiker-thecubicle,
  author   = {The Cubicle},
  title    = {XiaoMi Giiker Cube},
  url      = {https://www.thecubicle.com/products/xiaomi-giiker-cube/},
  addendum = {(accessed: 25 Sep 2021)}
}

@online{gocube-product-launch-video,
  author   = {Go Cube},
  title    = {Go Cube - Official Kickstarter Video},
  url      = {https://www.youtube.com/watch?v=tMtmzoC_WUY},
  addendum = {(accessed: 26 Sep 2021)}
}

@online{gocube-rubiksconnected,
  author   = {Go Cube},
  title    = {Rubik's Connected},
  url      = {https://www.getgocube.com/products/rubiks-connected/},
  addendum = {(accessed: 27 Sep 2021)}
}

@online{gans356i-thecubicle,
  author   = {The Cubicle},
  title    = {Gan 356 I},
  url      = {https://www.thecubicle.com/products/gan-356i},
  addendum = {(accessed: 26 Sep 2021)}
}

@inproceedings{polfreman-musiccube,
  author    = {Polfreman, Richard and Oliver, Benjamin},
  title     = {Rubik's Cube: Music's Cube},
  booktitle = {NIME Conference Proceedings},
  editor    = {},
  year      = {2017},
  month     = {04}
}

@inproceedings{mannone-cubeharmonic-2018,
  title     = {CubeHarmonic: A New Interface from a Magnetic 3D Motion Tracking System to Music Performance},
  author    = {Maria Mannone and Eri Kitamura and Jiawei Huang and Ryo Sugawara and Yoshifumi Kitamura},
  booktitle = {NIME Conference Proceedings},
  year      = {2018}
}

@article{mannone-cubeharmonic-2019,
  title   = {CubeHarmonic: a new musical instrument based on Rubik's cube with embedded motion sensor},
  author  = {Maria Mannone and Eri Kitamura and Jiawei Huang and Ryo Sugawara and Pascal Chiu and Yoshifumi Kitamura},
  journal = {ACM SIGGRAPH 2019 Posters},
  year    = {2019}
}

@inproceedings{im3d,
  author    = {Huang, Jiawei and Takashima, Kazuki and Hashi, Shuichiro and Kitamura, Yoshifumi},
  title     = {IM3D: Magnetic Motion Tracking System for Dexterous 3D Interactions},
  year      = {2014},
  isbn      = {9781450329613},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi-org.ezproxy1.lib.asu.edu/10.1145/2614066.2614084},
  doi       = {10.1145/2614066.2614084},
  abstract  = {3D motion tracking is one key technology in computer animation, virtual reality, natural
user interface, and so on. Over the last thirty years numerous projects with various
approaches have developed motion tracking systems, including mechanical, ultrasonic,
magnetic, and optical schemes. Recently, interest has also been growing in the motion
tracking of small targets in complex environments and tracking subtle movements. For
example, the behavior analysis of insects or other small creatures in the earth will
contribute to the growth of biology or related sciences, and the precise analysis
of dexterous finger motions will be useful for professional techniques or the skills
required for traditional handcrafts or medical procedures. Unfortunately, common existing
tracking systems cannot satisfy the requirements of these tasks because the targets
are too small and their motions are complex and easily occluded.},
  booktitle = {ACM SIGGRAPH 2014 Emerging Technologies},
  articleno = {12},
  numpages  = {1},
  location  = {Vancouver, Canada},
  series    = {SIGGRAPH '14}
}

@online{speedsolving-com,
  author   = {SpeedSolving.com},
  title    = {Home Page},
  url      = {https://www.speedsolving.com/},
  addendum = {(accessed: 28 Sep 2021)}
}
@online{googleplay-twistytimer,
  author   = {Ari Neto},
  title    = {Twisty Timer},
  url      = {https://play.google.com/store/apps/details?id=com.aricneto.twistytimer},
  addendum = {(accessed: 28 Sep 2021)}
}

@online{michel-sound,
  author   = {Michel, Jonas},
  title    = {mobile-acoustic-modems-in-action Wiki},
  url      = {https://github.com/jonasrmichel/mobile-acoustic-modems-in-action/wiki/Wiki},
  addendum = {(accessed: 28 Sep 2021)}
}

@online{fda-rfid,
  author   = {The Food and Drug Administration},
  title    = {Radio Frequency Identification (RFID)},
  url      = {https://www.fda.gov/radiation-emitting-products/electromagnetic-compatibility-emc/radio-frequency-identification-rfid},
  addendum = {(accessed: 28 Sep 2021)}
}

@online{nve-mag-sensor,
  author   = {NVE Corporation},
  title    = {Off-Axis Angle Sensing with NVE Angle Sensors},
  url      = {https://www.nve.com/Downloads/SB-SA-02_Off-Axis-Angle-Sensing.pdf},
  addendum = {(accessed: 06 June 2020)}
}

@online{nve-mag-sensor-calculations,
  author   = {NVE Corporation},
  title    = {Calculators/WebApps: Off-Axis Angle Sensing},
  url      = {https://www.nve.com/spec/calculators#tabs-Off-Axis-Angle-Sensing},
  addendum = {(accessed: 06 June 2020)}
}

@article{rfid-rotary-encoder,
  author         = {Genovesi, Simone and Costa, Filippo and Borgese, Michele and Dicandia, Francesco Alessio and Manara, Giuliano},
  title          = {Chipless Radio Frequency Identification (RFID) Sensor for Angular Rotation Monitoring},
  journal        = {Technologies},
  volume         = {6},
  year           = {2018},
  number         = {3},
  article-number = {61},
  url            = {https://www.mdpi.com/2227-7080/6/3/61},
  issn           = {2227-7080},
  abstract       = {A novel, chipless, Radio Frequency Identification (RFID) sensor is proposed for monitoring angular rotation. The rotation state is recovered by collecting the cross polar response of a tag, based on a periodic surface composed of a set of dipoles. The encoding mechanism allows the sensor to be very robust, even if it is applied on metallic objects, or in an environment with strong multipath. The proposed sensor does not require a large operational bandwidth. Instead, only a small set of reading frequencies are required. The number of reading frequencies required is dependent on the number of the employed dipoles. It is demonstrated that the rotation state of an object can be monitored within a span of 180 degrees, with up to a three-degree resolution, by employing a chipless RFID sensor comprising of four dipoles. The far field reading scheme and the absence of any electronics device allow the sensor to be employed in harsh environments.},
  doi            = {10.3390/technologies6030061}
}
